---
marp: true
theme: default
paginate: true
header: LeanConjecturer: Automatic Generation of Mathematical Conjectures
footer: arXiv:2506.22005v1
size: 16:9
style: |
  section {
    font-size: 24px;
  }
  h1 {
    font-size: 40px;
    color: #2b557a;
  }
  h2 {
    font-size: 32px;
    color: #2b557a;
  }
  h3 {
    font-size: 28px;
    color: #444;
  }
  strong {
    color: #d63031;
    font-weight: bold;
  }
---

# LeanConjecturer:
## 自動定理証明のための数学的予想の自動生成

**論文:** arXiv:2506.22005v1 [cs.AI]
**著者:** Naoto Onda et al.

---

# 第1部：研究背景と課題
### なぜ今、自動予想生成が必要なのか？

---

## 1.1 LLMによる形式的定理証明の進展

近年、大規模言語モデル（LLM）は形式的定理証明（Formal Theorem Proving）において目覚ましい成果を上げています。これはAIシステムの信頼性と推論能力を保証する上で重要な分野です。

* **DeepSeek-Prover-V2 の実績**:
    * **MiniF2F-test**: 88.9% という驚異的なパス率を達成。
    * **PutnamBench**: 難関なパトナム数学競争の問題において、658問中49問を解決。
    * AIMEのような高度な数学問題においても、その推論能力を実証しています。

これらの成果は、AIが複雑な論理タスクにおいて人間並み、あるいはそれ以上の能力を獲得しつつあることを示唆しています。

---

## 1.2 形式的数学データの希少性 (1)

LLMの成功の裏には、**深刻なデータ不足**というボトルネックが存在します。ここには大きな格差があります。

* **非形式的データ（Informal Mathematics）**:
    * 自然言語で書かれた数学テキスト（教科書、論文、Web記事など）は数テラバイト規模で存在し、LLMの事前学習に広く利用されています。
* **形式的データ（Formal Mathematics）**:
    * Leanなどの証明支援系言語で記述されたデータは極めて希少です。
    * Leanの標準ライブラリである **Mathlib** をすべて合わせても、そのデータ量は **1GB未満** に過ぎません。

---

## 1.3 形式的数学データの希少性 (2)

なぜ形式的データは増えないのでしょうか？

* **圧倒的な作成コスト**:
    * 自然言語による数学的推論を、機械が検証可能な証明コードに変換する「形式化」作業は、極めて労働集約的です。
    * 熟練した数学者であっても、論理の全ステップにおいて極限の精度が求められるため、1つの定理を形式化するのに多大な時間を要します。
* **ファインチューニングへの影響**:
    * データへの大量暴露によって性能を向上させる現代のLLMにとって、1GB未満のデータセットは効果的な学習を行うには不十分です。

---

## 1.4 自明性の罠 (The Triviality Trap)

データを自動生成しようとする際、陥りやすい罠があります。

* **自明な命題の大量生産**:
    * 構文的に正しいだけの定理を生成することは容易です（例：「AならばAである」）。
    * しかし、これらは数学的に面白みがなく、学習データとしての価値が低いため、モデルの能力向上に寄与しません。
* **本研究の狙い**:
    * 「構文的に正しく」かつ「数学的に自明ではない（証明が簡単すぎない）」予想を生成すること。
    * 既存の証明を必要とせず、**予想（Conjectures）** のステートメント自体を生成するアプローチを採用し、コストを削減します。

---

# 第2部：関連研究の詳細
### 既存のアプローチとその限界

---

## 2.1 関連研究: LLMを用いた定理証明

LLMを証明支援系（ITP）に統合する試みが急速に進んでいます。

* **パイプラインアプローチ**:
    * DeepSeek-V3 (671Bモデル) が証明のサブゴール分解（証明の設計図作成）を行い、DeepSeek-Prover-V2 (7Bモデル) が個々の証明を行うといった、モデルの役割分担による解決策が提案されています。
* **Hammers (自動化ツール)**:
    * `Lean-auto` などのツールは、Leanの論理システム（依存型理論）と外部の自動定理証明機（ATP）を翻訳・接続し、証明の自動化を強力に支援しています。

---

## 2.2 関連研究: 自動形式化 (Autoformalization)

データ不足への対策として、自然言語の数学問題を自動的に形式化する手法が注目されています。

* **Lean Workbook (2024)**:
    * 自然言語の問題集をLLMを用いて形式化し、トレーニングデータとして有効であることを示しました。
* **限界**:
    * 対象がIMO（国際数学オリンピック）などの**競技数学に偏っています**。
    * これらは短く自己完結した問題が多く、Mathlibに含まれるような**現代数学の高度で抽象的な理論**（大学レベル以上の数学）をカバーできていません。
    * 結果として、モデルが特定の「競技スタイル」に過剰適合するリスクがあります。

---

## 2.3 関連研究: 合成データの生成

既存のライブラリから新しいデータを「合成」する試みもあります。

* **LeanNavigator (2025)**:
    * **状態グラフ探索**を用い、Mathlib内の既存の証明から状態遷移グラフを構築。
    * 異なる証明パスを体系的に探索することで、470万の定理（10億トークン相当）を生成しました。
* **貢献**:
    * 代替的な証明ルートや、ライブラリ内に隠れた数学的関係性を発見する手段として有効です。

---

## 2.4 関連研究: Self-Play (自己対局)

データ枯渇を解決する最新のブレイクスルーとして、**Self-Play（自己対局）** が提案されています。

* **STP (Self-play Theorem Prover, 2025)**:
    * LLMが「予想者 (Conjecturer)」と「証明者 (Prover)」の二役を担います。
    * **Barely Provable**: 現在の証明者にとって「ギリギリ証明できる」難易度の予想を生成し、相互に学習を進めます。
    * 人間が新しい結果を発見するプロセスを模倣し、静的なデータセットの限界を超えようとしています。

---

## 2.5 Self-Playの課題と本研究の位置づけ

Self-Playは有望ですが、以下の課題が残されています。

1.  **モード崩壊 (Mode Collapse)**: 多様なシードを与えても、生成される予想が特定のトピックに偏る傾向があります。
2.  **学習の不安定性**: 自己対局中にデータ分布が動的に変化するため、学習が安定しません。
3.  **フィルタリングの質**: 「エレガントさ」を判定するヒューリスティックなフィルタに依存しており、数学的な重要性を捉えきれない場合があります。

**LeanConjecturer** は、Mathlibを直接のインスピレーション源とすることで、**多様性を維持しつつ、大学レベルの数学的予想を安定して生成**することを目指します。

---

# 第3部：提案手法 LeanConjecturer
### ハイブリッド生成パイプライン

---

## 3.1 手法の概要

LeanConjecturerは、Mathlibファイルを「種」として利用し、大学レベルの数学的予想を生成するパイプラインです。

1.  **入力**: Mathlibファイル。
2.  **ハイブリッド生成**:
    * **ルールベース**: 文脈（定義や名前空間）の抽出、import管理。
    * **LLM**: 定理のステートメント生成に特化。証明やコンテキストは生成させない。
3.  **反復プロセス**: 生成物を次の入力にフィードバックし、連鎖的に予想を生み出す。

---

## 3.2 構造化された生成プロンプト

LLM（実験ではOpenAI o3を使用）には、証明を含めず、定理の宣言のみを行わせます。

* **プロンプトの工夫**: `"as many as possible"`（できるだけ多く）という指示を含めることが重要です。
    * これにより、入力ファイルが短い（例：定理が1つ）場合でも、大量の予想を生成させることが可能になります。
    * 指示がない場合、入力の定理数に引きずられ、生成数が激減する現象が確認されました。
* **後処理**:
    * 生成されたテキストから構文的な装飾を除去。
    * ルールベースで `import Mathlib`, `import Aesop` などを付与し、実行可能なLeanコードに整形します。

---

## 3.3 厳格な評価プロセス

生成された予想は、以下の3段階でフィルタリングされます。

1.  **構文的妥当性 (Syntactic Validity)**:
    * Lean 4コンパイラでパース可能か確認します。証明部分を `sorry` に置き換えてエラーが出なければ合格です。
2.  **新規性 (Novelty)**:
    * `exact?` タクティクを使用し、既存のMathlibの定理で自明に証明できないか確認します。
    * また、過去に生成した予想とも比較し、重複を排除します。
3.  **非自明性 (Non-Triviality)**:
    * 自動証明タクティク `aesop` で証明を試みます。
    * `aesop` で**証明できない**場合、「非自明」とみなし、高難易度のデータとして扱います。

---

## 3.4 反復による多様性の確保

* **反復生成 (Iteration)**:
    * 有効かつ新規と判定された予想をファイルに追記し、次の生成ラウンドのコンテキストとして使用します。
* **コンテキスト管理の効果**:
    * コンテキストに過去の生成物を含めることで、LLMが同じパターンを繰り返すのを防ぎます。
    * これにより、既出の定理とは異なる、より深い数学的構造を持つ予想へとモデルを誘導します。
* 実験では最大15回の反復を行い、多様な予想を蓄積しました。

---

# 第4部：実験結果と検証
### 生成量、質、そして強化学習への応用

---

## 4.1 予想生成の規模と効率

Mathlibから選定した40ファイルをシードとした実験結果は以下の通りです。

* **総生成数**: 12,289 個
* **構文的に有効**: 10,950 個
* **新規 (Novel)**: 4,130 個
* **非自明 (Non-Trivial)**: **3,776 個**
    * これらは `aesop` では証明できず、かつ既存のMathlibにはない新しい命題です。

1ファイルあたり平均 **103.25個** の新規予想を生成でき、高いスケーラビリティを示しました。これは、手動でのデータ作成に比べて圧倒的に効率的です。

---

## 4.2 強化学習 (GRPO) による能力向上

生成された予想（トポロジー分野）を用いて、DeepSeek-Prover-V2を強化学習（GRPO: Group Relative Policy Optimization）させました。

* **ターゲット**: 内部 (interior) と閉包 (closure) に関する192問。
* **報酬関数**: 証明成功で1、失敗で0のバイナリ報酬。

| モデル | 証明成功率 (Proof Rate) |
| :--- | :--- |
| ベースモデル (V2-7B) | 9.3% (2285/24576) |
| **GRPO (10 epochs)** | **14.9%** (3657/24576) |
| **+追加学習 (24 epochs)** | **21.6%** (5307/24576) |

---

## 4.3 学習曲線と汎化性能

* **学習の進捗**:
    * 34エポックを通じて報酬（証明成功率）は右肩上がりに推移しました。モデルがドメイン固有の推論パターンを学習していることを示します。
* **汎化性能の検証**:
    * 学習データに含まれない「alpha-open set」に関する問題でもテストを実施しました。
    * 証明成功数がベースラインの466から536へ増加しました。
    * 完全な汎化とまでは言えませんが、関連する概念へのある程度のスキル移転が確認されました。

---

## 4.4 発見された定理の例

LeanConjecturerは、以下のようなトポロジーの概念に関する新しい定理を生成し、検証しました。

~~~lean
-- Pre-open集合の閉包はSemi-openであるという新しい定理
theorem closure_pre_open_is_semi_open (A : Set X) (h : PreOpen A)
  : SemiOpen (closure A) := by
  -- 定義の展開とタウトロジーによる証明
  simp_all [SemiOpen, PreOpen, closure_mono, interior_mono, subset_closure]
  <;> tauto
~~~

* **Semi-open**: $A \subseteq \text{closure}(\text{interior } A)$
* **Pre-open**: $A \subseteq \text{interior}(\text{closure } A)$
* これらの概念間の非自明な包含関係などを自動的に予想することに成功しました。

---

# 第5部：結論と展望

---

## 5.1 結論

* **LeanConjecturer** は、LLMとルールベース手法を融合させ、質の高い数学的予想を大量生成するスケーラブルなパイプラインです。
* 既存研究（AutoformalizationやSelf-Play）の課題であった「競技数学への偏り」や「モード崩壊」を、Mathlibをシードとすることで克服するアプローチを提示しました。
* 生成データを用いた強化学習により、定理証明能力の向上が確認され、AIによる数学的発見（Mathematical Discovery）への道を開きました。

---

## 5.2 限界と今後の課題

* **真偽判定の自動化**:
    * 現在は生成された予想の真偽確認を、外部の証明器（DeepSeek-Prover-V2）に依存しています。
* **シードへの依存**:
    * 生成される予想の質は、入力ファイルの質や多様性に影響を受けます。
* **計算コスト**:
    * GRPOの学習には依然として多大な計算リソース（A100 GPUなど）が必要です。

---

## 5.3 今後の展望

* **シードの拡大**:
    * Mathlib全体（約6,000ファイル）への適用による、より広範な数学領域のカバー。
* **Self-Playとの統合**:
    * LeanConjecturerの多様性と、STPの自己改善ループを組み合わせたハイブリッドシステムの構築。
* **探索的生成**:
    * 未探索の数学的領域へLLMを積極的に誘導するプロンプト技術の開発。

---

**ご清聴ありがとうございました**